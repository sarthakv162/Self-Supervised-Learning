{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3814e6ec",
   "metadata": {},
   "source": [
    "# Momentum Contrast (MoCo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "import copy\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for rd in [\n",
    "    \"/kaggle/input/ssl-dataset/ssl_dataset/train.X1\",\n",
    "    \"/kaggle/input/ssl-dataset/ssl_dataset/train.X2\",\n",
    "    \"/kaggle/input/ssl-dataset/ssl_dataset/train.X3\",\n",
    "    \"/kaggle/input/ssl-dataset/ssl_dataset/train.X4\"\n",
    "]:\n",
    "    print(f\"\\nContents of {rd}:\")\n",
    "    for name in sorted(os.listdir(rd)):\n",
    "        path = os.path.join(rd, name)\n",
    "        if os.path.isdir(path):\n",
    "            print(f\"  [DIR]  {name}  â†’  contains {len(os.listdir(path))} entries\")\n",
    "        else:\n",
    "            print(f\"  [FILE] {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bd383",
   "metadata": {},
   "source": [
    "## Parameters and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRS = [\"/kaggle/input/ssl-dataset/ssl_dataset/train.X1\", \"/kaggle/input/ssl-dataset/ssl_dataset/train.X2\", \"/kaggle/input/ssl-dataset/ssl_dataset/train.X3\", \"/kaggle/input/ssl-dataset/ssl_dataset/train.X4\"]\n",
    "IMG_SIZE    = 80\n",
    "BATCH_SIZE  = 64\n",
    "EMB_DIM     = 128\n",
    "HEAD_DIM    = 512\n",
    "QUEUE_SIZE  = 4096\n",
    "MOMENTUM    = 0.999\n",
    "TEMPERATURE = 0.07\n",
    "LR          = 0.03 * (BATCH_SIZE / 256)\n",
    "EPOCHS      = 100\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ce172",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b47713",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.4,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.4,0.4,0.4,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "class ContrastiveDS(Dataset):\n",
    "    def __init__(self, roots, tfm):\n",
    "        self.paths = []\n",
    "        for rd in roots:\n",
    "            for r, _, fn in os.walk(rd):\n",
    "                for f in fn:\n",
    "                    if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
    "                        self.paths.append(os.path.join(r,f))\n",
    "        assert self.paths, \"No images found\"\n",
    "        self.tfm = tfm\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self,i):\n",
    "        img = Image.open(self.paths[i]).convert(\"RGB\")\n",
    "        return self.tfm(img), self.tfm(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 90000\n",
    "ds_full = ContrastiveDS(TRAIN_DIRS, aug)\n",
    "subset_indices = random.sample(range(len(ds_full)), NUM_SAMPLES)\n",
    "ds = Subset(ds_full, subset_indices)\n",
    "\n",
    "\n",
    "loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                    num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "print(\"Samples:\", len(ds)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a1e23",
   "metadata": {},
   "source": [
    "## MoCo Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c16a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoCo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=False)\n",
    "        feat_dim = base.fc.in_features  # 512 for ResNet18\n",
    "        self.encoder_q = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.encoder_k = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.projector_q = nn.Sequential(\n",
    "            nn.Linear(feat_dim, HEAD_DIM),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(HEAD_DIM, EMB_DIM)\n",
    "        )\n",
    "        self.projector_k = copy.deepcopy(self.projector_q)\n",
    "        self.m, self.T = MOMENTUM, TEMPERATURE\n",
    "\n",
    "        for q, k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            k.data.copy_(q.data); k.requires_grad=False\n",
    "        for q, k in zip(self.projector_q.parameters(), self.projector_k.parameters()):\n",
    "            k.data.copy_(q.data); k.requires_grad=False\n",
    "\n",
    "     \n",
    "        self.register_buffer(\"queue\", torch.zeros(EMB_DIM, QUEUE_SIZE))\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_key(self):\n",
    "        for q, k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            k.data = k.data*self.m + q.data*(1-self.m)\n",
    "        for q, k in zip(self.projector_q.parameters(), self.projector_k.parameters()):\n",
    "            k.data = k.data*self.m + q.data*(1-self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _enqueue(self, keys):\n",
    "        B = keys.size(0); ptr = int(self.queue_ptr); K = self.queue.size(1)\n",
    "        qk = keys.T\n",
    "        if ptr + B <= K:\n",
    "            self.queue[:, ptr:ptr+B] = qk\n",
    "        else:\n",
    "            first = K - ptr\n",
    "            self.queue[:, ptr:]    = qk[:, :first]\n",
    "            self.queue[:, :B-first] = qk[:, first:]\n",
    "        self.queue_ptr[0] = (ptr + B) % K\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "  \n",
    "        qf = self.encoder_q(x1).flatten(1)\n",
    "        q  = F.normalize(self.projector_q(qf), dim=1)\n",
    "\n",
    "   \n",
    "        with torch.no_grad():\n",
    "            self._update_key()\n",
    "            kf = self.encoder_k(x2).flatten(1)\n",
    "            k  = F.normalize(self.projector_k(kf), dim=1)\n",
    "\n",
    "    \n",
    "        queue_const = self.queue.clone().detach().to(q.device)\n",
    "\n",
    "   \n",
    "        l_pos  = (q * k).sum(1, True)\n",
    "        l_neg  = q @ queue_const     \n",
    "        logits = torch.cat([l_pos, l_neg], dim=1) / self.T\n",
    "        labels = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device)\n",
    "\n",
    "        self._enqueue(k)\n",
    "        return logits, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4f3ef",
   "metadata": {},
   "source": [
    "## Pre-Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"/kaggle/working/\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "moco = MoCo().to(DEVICE, memory_format=torch.channels_last)\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(\"Model parameters on:\", next(moco.parameters()).device)\n",
    "\n",
    "opt = torch.optim.SGD(\n",
    "    list(moco.encoder_q.parameters()) + list(moco.projector_q.parameters()),\n",
    "    lr=LR, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2)\n",
    "scaler = GradScaler()\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience = 5\n",
    "wait = 0\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    moco.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"Epoch {ep}/{EPOCHS}\", leave=False)\n",
    "    for a, b in pbar:\n",
    "        a = a.to(DEVICE, non_blocking=True)\n",
    "        b = b.to(DEVICE, non_blocking=True)\n",
    "        batch_size = a.size(0)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        with autocast():\n",
    "            logits, labs = moco(a, b)\n",
    "            loss = F.cross_entropy(logits, labs)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    sch.step()\n",
    "    avg_loss = running_loss / total_samples\n",
    "    epoch_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {ep}/{EPOCHS}  Avg Loss: {avg_loss:.4f}  LR: {opt.param_groups[0]['lr']:.6f}\", flush=True)\n",
    "\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        wait = 0\n",
    "        torch.save(moco.state_dict(), f\"{SAVE_DIR}/best.pth\")\n",
    "        print(f\"ðŸ”¥ New best model @ epoch {ep}: {best_loss:.4f}\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"â›” Early stopping triggered @ epoch {ep}\")\n",
    "            break\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': ep,\n",
    "        'model_state_dict': moco.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "        'lr': opt.param_groups[0]['lr']\n",
    "    }, f\"{SAVE_DIR}/checkpoint_epoch_{ep}.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
