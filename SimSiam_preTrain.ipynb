{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d96cdd5",
   "metadata": {},
   "source": [
    "# SimSiam Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40acb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_ROOT = \"/kaggle/input/ssl-dataset/ssl_dataset\"\n",
    "TRAIN_FOLDERS = [f\"train.X{i}\" for i in range(1, 5)]\n",
    "VAL_FOLDER = \"val.X\"\n",
    "\n",
    "BATCH_SIZE = 64       \n",
    "NUM_WORKERS = 2        \n",
    "EPOCHS = 50\n",
    "BASE_LR = 0.05         \n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "CHECKPOINT_DIR = \"/kaggle/working/\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a502d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionMLP(nn.Module):\n",
    "    def __init__(self, in_dim=512, hidden_dim=512, out_dim=512):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, out_dim, bias=False),\n",
    "            nn.BatchNorm1d(out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "    \n",
    "class PredictionMLP(nn.Module):\n",
    "    def __init__(self, in_dim=512, hidden_dim=256, out_dim=512):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# SimSiam with ResNet‑18 backbone\n",
    "\n",
    "class SimSiam(nn.Module):\n",
    "    def __init__(self, backbone=\"resnet18\", pretrained_backbone=False):\n",
    "        super().__init__()\n",
    "        if backbone == \"resnet18\":\n",
    "            base = models.resnet18(pretrained=pretrained_backbone)\n",
    "            \n",
    "            self.encoder = nn.Sequential(*list(base.children())[:-1])\n",
    "            feat_dim = base.fc.in_features \n",
    "        else:\n",
    "            raise NotImplementedError(\"Only resnet18 is supported here.\")\n",
    "\n",
    "       \n",
    "        self.projector = ProjectionMLP(in_dim=feat_dim,\n",
    "                                       hidden_dim=feat_dim,\n",
    "                                       out_dim=feat_dim)\n",
    "        \n",
    "        self.predictor = PredictionMLP(in_dim=feat_dim,\n",
    "                                       hidden_dim=256,\n",
    "                                       out_dim=feat_dim)\n",
    "\n",
    "    def forward_backbone(self, x):\n",
    "        feat = self.encoder(x)          \n",
    "        feat = torch.flatten(feat, 1)   \n",
    "        return feat\n",
    "\n",
    "    def forward(self, view1, view2):\n",
    "        f1 = self.forward_backbone(view1)  \n",
    "        f2 = self.forward_backbone(view2)\n",
    "\n",
    "        z1 = self.projector(f1)            \n",
    "        z2 = self.projector(f2)\n",
    "\n",
    "        p1 = self.predictor(z1)             \n",
    "        p2 = self.predictor(z2)\n",
    "\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "def simsiam_loss(p, z):\n",
    "    p = F.normalize(p, dim=1)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    return - (p * z).sum(dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825a9ba",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simsiam_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "class SimSiamDataset(Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.base[idx]\n",
    "        view1 = self.transform(img)\n",
    "        view2 = self.transform(img)\n",
    "        return view1, view2\n",
    "\n",
    "\n",
    "train_datasets = []\n",
    "for folder in TRAIN_FOLDERS:\n",
    "    full_path = os.path.join(DATA_ROOT, folder)\n",
    "    train_datasets.append(datasets.ImageFolder(full_path, transform=None))\n",
    "\n",
    "\n",
    "combined_train = ConcatDataset(train_datasets)\n",
    "total_samples = len(combined_train)   \n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "all_indices = list(range(total_samples))\n",
    "subsample_size = 50_000\n",
    "subsample_indices = random.sample(all_indices, subsample_size)\n",
    "\n",
    "\n",
    "subsampled_train = Subset(combined_train, subsample_indices)\n",
    "\n",
    "\n",
    "simsiam_train = SimSiamDataset(subsampled_train, simsiam_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    simsiam_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    os.path.join(DATA_ROOT, VAL_FOLDER),\n",
    "    transform=val_transform\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093a546",
   "metadata": {},
   "source": [
    "## Model formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimSiam(backbone=\"resnet18\", pretrained_backbone=False).to(DEVICE)\n",
    "\n",
    "optimizer = SGD(\n",
    "    model.parameters(),\n",
    "    lr=BASE_LR,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    for (view1, view2) in tqdm(loader, desc=\"Pretrain SimSiam\"):\n",
    "        view1 = view1.to(DEVICE, non_blocking=True)\n",
    "        view2 = view2.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            p1, p2, z1, z2 = model(view1, view2)\n",
    "            loss1 = simsiam_loss(p1, z2)\n",
    "            loss2 = simsiam_loss(p2, z1)\n",
    "            loss = 0.5 * (loss1 + loss2)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        batch_sz = view1.size(0)\n",
    "        total_loss += loss.item() * batch_sz\n",
    "        num_samples += batch_sz\n",
    "\n",
    "    return total_loss / num_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de58ccd",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float(\"inf\")\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_loss = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{EPOCHS}]  Pretrain Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "    \n",
    "    ckpt_path = os.path.join(CHECKPOINT_DIR, f\"simsiam_r18_epoch{epoch}.pth\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"loss\": epoch_loss,\n",
    "    }, ckpt_path)\n",
    "\n",
    "  \n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "\n",
    "print(\"→ Pretraining complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
