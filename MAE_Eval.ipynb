{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d6ff22",
   "metadata": {},
   "source": [
    "# MAE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731368ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = \"/kaggle/input/ssl-dataset/ssl_dataset\"\n",
    "CHECKPOINT_PATH = \"/kaggle/input/mae_save/pytorch/default/1/mae_checkpoint_epoch9.pth\"\n",
    "VAL_FOLDER = \"val.X\"\n",
    "LABELS_PATH = os.path.join(DATA_ROOT, \"Labels.json\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# --- MAE Model Loading ---\n",
    "class CustomMAE(nn.Module):\n",
    "    def __init__(self, encoder, patch_embed, pos_embed, encoder_blocks, \n",
    "                 encoder_norm, mask_token, decoder, reconstruction_head):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.patch_embed = patch_embed\n",
    "        self.pos_embed = pos_embed\n",
    "        self.encoder_blocks = encoder_blocks\n",
    "        self.encoder_norm = encoder_norm\n",
    "        self.mask_token = mask_token\n",
    "        self.decoder = decoder\n",
    "        self.reconstruction_head = reconstruction_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement your forward pass here\n",
    "        pass\n",
    "\n",
    "    def get_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = x + self.pos_embed[:, 1:, :]  # Skip cls token\n",
    "        for blk in self.encoder_blocks:\n",
    "            x = blk(x)\n",
    "        x = self.encoder_norm(x)\n",
    "        return x.mean(dim=1)  # Global average pooling\n",
    "\n",
    "# Initialize model components\n",
    "encoder = timm.create_model('vit_tiny_patch16_224', pretrained=False)\n",
    "encoder.reset_classifier(0)  # Remove classification head\n",
    "\n",
    "# Extract components\n",
    "patch_embed = encoder.patch_embed\n",
    "pos_embed = encoder.pos_embed\n",
    "encoder_blocks = encoder.blocks\n",
    "encoder_norm = encoder.norm\n",
    "embed_dim = encoder.embed_dim\n",
    "\n",
    "# MAE-specific components\n",
    "mask_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "decoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=embed_dim,\n",
    "    nhead=4,\n",
    "    dim_feedforward=embed_dim*2,\n",
    "    batch_first=True\n",
    ")\n",
    "decoder = nn.TransformerEncoder(decoder_layer, num_layers=4)\n",
    "reconstruction_head = nn.Linear(embed_dim, 16*16*3)  # For 16x16 patches\n",
    "\n",
    "# Initialize model\n",
    "model = CustomMAE(\n",
    "    encoder=encoder,\n",
    "    patch_embed=patch_embed,\n",
    "    pos_embed=pos_embed,\n",
    "    encoder_blocks=encoder_blocks,\n",
    "    encoder_norm=encoder_norm,\n",
    "    mask_token=mask_token,\n",
    "    decoder=decoder,\n",
    "    reconstruction_head=reconstruction_head\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class MAEEvalDataset(Dataset):\n",
    "    def __init__(self, folder_path, label_dict, transform):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = sorted(list(set(label_dict.values())))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.class_names)}\n",
    "        \n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    class_folder = os.path.basename(root)\n",
    "                    if class_folder in label_dict:\n",
    "                        self.image_paths.append(os.path.join(root, file))\n",
    "                        self.labels.append(self.class_to_idx[label_dict[class_folder]])\n",
    "        \n",
    "        self.transform = transform\n",
    "        print(f\"Found {len(self.image_paths)} labeled images across {len(self.class_names)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {self.image_paths[idx]}: {str(e)}\")\n",
    "            return torch.zeros(3, IMG_SIZE, IMG_SIZE), -1\n",
    "\n",
    "# --- Transformations ---\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- Load Labels and Dataset ---\n",
    "with open(LABELS_PATH) as f:\n",
    "    label_dict = json.load(f)\n",
    "\n",
    "val_dataset = MAEEvalDataset(\n",
    "    folder_path=os.path.join(DATA_ROOT, VAL_FOLDER),\n",
    "    label_dict=label_dict,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(f\"Total validation images: {len(val_dataset)}\")\n",
    "\n",
    "# --- Feature Extraction ---\n",
    "def extract_features(loader):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc=\"Extracting features\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model.get_features(imgs).cpu()\n",
    "            features.append(feats)\n",
    "            labels.append(lbls)\n",
    "    \n",
    "    features = torch.cat(features)\n",
    "    labels = torch.cat(labels)\n",
    "    \n",
    "    # Remove invalid samples (label == -1)\n",
    "    valid_idx = labels != -1\n",
    "    return features[valid_idx], labels[valid_idx]\n",
    "\n",
    "X_val, y_val = extract_features(val_loader)\n",
    "print(f\"Feature shape: {X_val.shape}, Labels shape: {y_val.shape}\")\n",
    "\n",
    "# --- Linear Probing ---\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_val.numpy(), y_val.numpy())\n",
    "\n",
    "# --- Evaluation ---\n",
    "val_preds = clf.predict(X_val.numpy())\n",
    "acc = accuracy_score(y_val.numpy(), val_preds)\n",
    "f1 = f1_score(y_val.numpy(), val_preds, average='macro')\n",
    "\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Macro F1 Score: {f1*100:.2f}%\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_val.numpy(), val_preds)\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix (Accuracy: {acc*100:.2f}%)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.savefig(\"/kaggle/working/confusion_matrix.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- Training History Visualization ---\n",
    "def plot_training_history():\n",
    "    # Try to get training history from checkpoint\n",
    "    if 'train_loss_history' in checkpoint and 'val_loss_history' in checkpoint:\n",
    "        train_loss = checkpoint['train_loss_history']\n",
    "        val_loss = checkpoint['val_loss_history']\n",
    "        train_acc = checkpoint.get('train_acc_history', [])\n",
    "        val_acc = checkpoint.get('val_acc_history', [])\n",
    "        \n",
    "        epochs = len(train_loss)\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(1, epochs+1), train_loss, label='Training Loss')\n",
    "        plt.plot(range(1, epochs+1), val_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "       \n",
    "        if train_acc and val_acc:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(range(1, epochs+1), train_acc, label='Training Accuracy')\n",
    "            plt.plot(range(1, epochs+1), val_acc, label='Validation Accuracy')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title('Training and Validation Accuracy')\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('/kaggle/working/training_history.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No training history found in checkpoint\")\n",
    "\n",
    "plot_training_history()\n",
    "\n",
    "# --- Save Results\n",
    "with open('/kaggle/working/results.txt', 'w') as f:\n",
    "    f.write(f\"Accuracy: {acc*100:.2f}%\\n\")\n",
    "    f.write(f\"Macro F1 Score: {f1*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795eafcd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
