{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462c64e9",
   "metadata": {},
   "source": [
    "# Momentum Contrast (MoCo) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743432ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/ssl-dataset/ssl_dataset\"\n",
    "CHECKPOINT_PATH = \"/kaggle/input/moco-model-epoch/pytorch/default/1/checkpoint_epoch.pth\"\n",
    "VAL_FOLDER = \"val.X\"\n",
    "LABELS_PATH = os.path.join(DATA_ROOT, \"Labels.json\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37439fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoCoBackbone(nn.Module):\n",
    "    def __init__(self, checkpoint_path):\n",
    "        super().__init__()\n",
    "      \n",
    "        base_encoder = models.resnet18(pretrained=False)\n",
    "        base_encoder.fc = nn.Identity()\n",
    "\n",
    "       \n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "        encoder_weights = {\n",
    "            k.replace(\"module.encoder_q.\", \"\").replace(\"encoder_q.\", \"\"): v\n",
    "            for k, v in state_dict.items()\n",
    "            if \"encoder_q\" in k or \"module.encoder_q\" in k\n",
    "        }\n",
    "\n",
    "        missing, unexpected = base_encoder.load_state_dict(encoder_weights, strict=False)\n",
    "\n",
    "        for param in base_encoder.parameters():\n",
    "            param.requires_grad = False  \n",
    "\n",
    "        self.encoder = base_encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.encoder(x)\n",
    "        return features\n",
    "\n",
    "model = MoCoBackbone(CHECKPOINT_PATH).to(device)\n",
    "model.eval()\n",
    "\n",
    "class MoCoEvalDataset(Dataset):\n",
    "    def __init__(self, folder_path, label_dict, transform):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = sorted(list(set(label_dict.values())))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.class_names)}\n",
    "\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    class_folder = os.path.basename(root)\n",
    "                    if class_folder in label_dict:\n",
    "                        self.image_paths.append(os.path.join(root, file))\n",
    "                        self.labels.append(self.class_to_idx[label_dict[class_folder]])\n",
    "\n",
    "        self.transform = transform\n",
    "        print(f\"Found {len(self.image_paths)} labeled images across {len(self.class_names)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {self.image_paths[idx]}: {str(e)}\")\n",
    "            return torch.zeros(3, IMG_SIZE, IMG_SIZE), -1\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "with open(LABELS_PATH) as f:\n",
    "    label_dict = json.load(f)\n",
    "\n",
    "val_dataset = MoCoEvalDataset(\n",
    "    folder_path=os.path.join(DATA_ROOT, VAL_FOLDER),\n",
    "    label_dict=label_dict,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(f\"Total validation images: {len(val_dataset)}\")\n",
    "\n",
    "def extract_features(loader):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc=\"Extracting features\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs).cpu()\n",
    "            features.append(feats)\n",
    "            labels.append(lbls)\n",
    "\n",
    "    features = torch.cat(features)\n",
    "    labels = torch.cat(labels)\n",
    "    valid_idx = labels != -1\n",
    "    return features[valid_idx], labels[valid_idx]\n",
    "\n",
    "X_val, y_val = extract_features(val_loader)\n",
    "print(f\"Feature shape: {X_val.shape}, Labels shape: {y_val.shape}\")\n",
    "\n",
    "# --- Linear Classifier ---\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_val.numpy(), y_val.numpy())\n",
    "\n",
    "val_probs = clf.predict_proba(X_val.numpy())\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_val.numpy(), val_preds)\n",
    "f1 = f1_score(y_val.numpy(), val_preds, average='macro')\n",
    "\n",
    "\n",
    "val_probs_tensor = torch.tensor(val_probs)\n",
    "true_labels_tensor = torch.tensor(y_val.numpy())\n",
    "\n",
    "top1_preds = torch.argmax(val_probs_tensor, dim=1)\n",
    "top1_correct = (top1_preds == true_labels_tensor).sum().item()\n",
    "top1_accuracy = top1_correct / len(y_val)\n",
    "\n",
    "top5_preds = torch.topk(val_probs_tensor, k=5, dim=1).indices\n",
    "top5_correct = torch.any(top5_preds == true_labels_tensor.unsqueeze(1), dim=1).sum().item()\n",
    "top5_accuracy = top5_correct / len(y_val)\n",
    "\n",
    "\n",
    "print(f\"\\nEvaluation Results (MoCo):\")\n",
    "print(f\"Accuracy (Top-1): {acc*100:.2f}%\")\n",
    "print(f\"Macro F1 Score: {f1*100:.2f}%\")\n",
    "print(f\"Top-1 Accuracy: {top1_accuracy*100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {top5_accuracy*100:.2f}%\")\n",
    "\n",
    "\n",
    "'''Evaluation Results (MoCo):\n",
    "Accuracy (Top-1): 46.20%\n",
    "Macro F1 Score: 45.58%\n",
    "Top-1 Accuracy: 46.20%\n",
    "Top-5 Accuracy: 73.96%'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
