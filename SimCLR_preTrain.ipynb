{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da548b4",
   "metadata": {},
   "source": [
    "# Task : Self-supervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b0ea5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "base_path = \"/kaggle/input/ssl-dataset/ssl_dataset\"\n",
    "train_dirs = [os.path.join(base_path, f\"train.X{i}\") for i in range(1, 5)]\n",
    "\n",
    "def get_all_image_paths():\n",
    "    image_paths = []\n",
    "    for train_dir in train_dirs:\n",
    "        for class_folder in os.listdir(train_dir):\n",
    "            class_path = os.path.join(train_dir, class_folder)\n",
    "            image_paths.extend(glob(os.path.join(class_path, \"*.JPEG\")))\n",
    "    return image_paths\n",
    "\n",
    "image_paths = get_all_image_paths()\n",
    "print(f\"Total Training Images: {len(image_paths)}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98895d78",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2914fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import random\n",
    "\n",
    "simclr_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(128),\n",
    "    transforms.RandomApply([transforms.ColorJitter()], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "class SimCLRDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = default_loader(self.image_paths[idx])\n",
    "        return self.transform(image), self.transform(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0619d",
   "metadata": {},
   "source": [
    "**To define SimCLR and Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56cb381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, base_model='resnet18', projection_dim=128):\n",
    "        super(SimCLRModel, self).__init__()\n",
    "        self.encoder = models.__dict__[base_model](pretrained=False)\n",
    "        num_ftrs = self.encoder.fc.in_features\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projector(features)\n",
    "        return projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
    "    z = torch.cat([z_i, z_j], dim=0)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "    sim /= temperature\n",
    "\n",
    "    N = z_i.shape[0]\n",
    "    labels = torch.arange(N).to(z.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    mask = torch.eye(2*N, dtype=torch.bool).to(z.device)\n",
    "    sim.masked_fill_(mask, -9e15)\n",
    "\n",
    "    positives = torch.cat([torch.diag(sim, N), torch.diag(sim, -N)], dim=0)\n",
    "    negatives = sim[~mask].view(2*N, -1)\n",
    "\n",
    "    logits = torch.cat([positives.unsqueeze(1), negatives], dim=1)\n",
    "    return F.cross_entropy(logits, torch.zeros(2*N, dtype=torch.long).to(z.device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99af3f",
   "metadata": {},
   "source": [
    "**TO TRAIN AND SAVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eee39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random \n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import json\n",
    "\n",
    "random.shuffle(image_paths)  \n",
    "dataset = SimCLRDataset(image_paths[:90000], simclr_transform)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=8)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimCLRModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 100\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs) \n",
    "\n",
    "loss_per_epoch = []  \n",
    "best_loss = float('inf')\n",
    "\n",
    "# ------------ Training Loop with Checkpointing ------------\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loader_tqdm = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for batch_idx, (x_i, x_j) in enumerate(loader_tqdm):\n",
    "        x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "        z_i, z_j = model(x_i), model(x_j)\n",
    "        loss = nt_xent_loss(z_i, z_j)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        avg_loss_so_far = total_loss / (batch_idx + 1)\n",
    "        loader_tqdm.set_postfix(loss=f\"{avg_loss_so_far:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} completed. Avg Loss: {avg_loss_so_far:.4f}\")\n",
    "    loss_per_epoch.append(avg_loss_so_far)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss_per_epoch': loss_per_epoch\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "\n",
    "    # Save best model\n",
    "    if avg_loss_so_far < best_loss:\n",
    "        best_loss = avg_loss_so_far\n",
    "        torch.save(model.state_dict(), 'simclr_best_model.pt')\n",
    "        print(f\"Best model saved at epoch {epoch+1} with loss {best_loss:.4f}\")\n",
    "\n",
    "# ------------ Save Loss Curve to JSON ------------\n",
    "with open('simclr_loss.json', 'w') as f:\n",
    "    json.dump(loss_per_epoch, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
